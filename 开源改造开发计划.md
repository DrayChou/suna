# Suna 全开源改造开发计划

## 项目概述

本计划旨在将 Suna 项目从依赖第三方商业服务改造为完全基于开源组件的解决方案，提高项目的自主可控性和降低运营成本。

## 当前第三方服务分析

### 核心依赖服务
1. **Supabase** - 数据库、认证、实时通信、文件存储
2. **Daytona** - 沙盒容器执行环境
3. **Tavily** - 网络搜索服务
4. **Firecrawl** - 网页抓取服务
5. **RapidAPI** - API服务聚合平台
6. **Langfuse** - LLM可观测性平台

### 基础设施服务
- Redis - 缓存服务（已开源）
- RabbitMQ - 消息队列（已开源）

## 开源替代方案选型

### 第一阶段：核心基础设施替换

#### 1. Supabase 替换方案
**选择：PostgreSQL + PostgREST + GoTrue + 自建实时服务**

**技术栈：**
- PostgreSQL 15+ - 主数据库
- PostgREST - 自动生成 REST API
- GoTrue - 用户认证服务
- MinIO - 对象存储服务
- WebSocket 服务 - 实时通信

**优势：**
- 完全兼容 Supabase API
- 性能可控
- 数据完全自主

#### 2. Daytona 替换方案
**选择：Docker + 自建沙盒管理服务**

**技术栈：**
- Docker Engine - 容器运行时
- Docker Compose - 容器编排
- 自建 Sandbox Manager - Python FastAPI 服务
- 资源限制和安全隔离

**功能特性：**
- 容器生命周期管理
- 资源监控和限制
- 安全隔离机制
- API 兼容层

### 第二阶段：服务功能替换

#### 3. Tavily 替换方案
**选择：SearXNG + 自建搜索聚合服务**

**技术栈：**
- SearXNG - 开源元搜索引擎
- 自建搜索 API 服务
- 结果缓存和优化

#### 4. Firecrawl 替换方案
**选择：Playwright + 自建爬虫服务**

**技术栈：**
- Playwright - 浏览器自动化
- 自建爬虫 API 服务
- 反爬虫策略
- 内容解析和清理

#### 5. RapidAPI 替换方案
**选择：直接 API 调用 + 自建数据源**

**策略：**
- 识别核心使用的 API
- 直接对接官方 API
- 开发统一的 API 管理层
- 集成开源数据源

### 第三阶段：监控和优化

#### 6. Langfuse 替换方案
**选择：自建监控系统**

**技术栈：**
- Prometheus - 指标收集
- Grafana - 可视化面板
- 自建 LLM 追踪服务
- 日志聚合和分析

## 详细实施计划

### 阶段一：核心基础设施（预计 4-6 周）

#### Week 1-2: Supabase 替换

**任务 1.1: 数据库迁移**
- [ ] 设置 PostgreSQL 15 实例
- [ ] 导出现有 Supabase 数据库结构
- [ ] 创建迁移脚本
- [ ] 数据迁移和验证

**任务 1.2: API 服务替换**
- [ ] 部署 PostgREST 服务
- [ ] 配置数据库权限和 RLS
- [ ] 创建 API 兼容层
- [ ] 测试现有 API 调用

**任务 1.3: 认证服务替换**
- [ ] 部署 GoTrue 服务
- [ ] 配置 JWT 和用户管理
- [ ] 迁移用户数据
- [ ] 测试登录和注册流程

**任务 1.4: 文件存储替换**
- [ ] 部署 MinIO 服务
- [ ] 配置存储桶和权限
- [ ] 迁移现有文件
- [ ] 更新文件上传/下载逻辑

**任务 1.5: 实时通信替换**
- [ ] 开发 WebSocket 服务
- [ ] 实现订阅和广播机制
- [ ] 集成到前端应用
- [ ] 测试实时功能

#### Week 3-4: Daytona 替换

**任务 2.1: 沙盒管理服务开发**
- [ ] 设计沙盒管理 API
- [ ] 实现容器生命周期管理
- [ ] 添加资源监控和限制
- [ ] 实现安全隔离机制

**任务 2.2: Docker 集成**
- [ ] 创建标准化容器镜像
- [ ] 配置网络和存储
- [ ] 实现容器编排
- [ ] 性能优化和调试

**任务 2.3: API 兼容层**
- [ ] 分析现有 Daytona API 调用
- [ ] 实现兼容的 API 接口
- [ ] 更新后端调用逻辑
- [ ] 集成测试和验证

#### Week 5-6: 系统集成和测试

**任务 3.1: 环境配置更新**
- [ ] 更新 docker-compose 配置
- [ ] 修改环境变量配置
- [ ] 更新部署脚本
- [ ] 文档更新

**任务 3.2: 端到端测试**
- [ ] 功能回归测试
- [ ] 性能基准测试
- [ ] 安全性测试
- [ ] 用户验收测试

### 阶段二：服务功能替换（预计 3-4 周）

#### Week 7-8: 搜索和爬虫服务

**任务 4.1: SearXNG 部署和配置**
- [ ] 部署 SearXNG 实例
- [ ] 配置搜索引擎源
- [ ] 开发搜索 API 包装器
- [ ] 结果格式化和缓存

**任务 4.2: 爬虫服务开发**
- [ ] 基于 Playwright 开发爬虫服务
- [ ] 实现反爬虫策略
- [ ] 添加内容解析和清理
- [ ] API 接口开发

#### Week 9-10: API 服务整合

**任务 5.1: RapidAPI 功能分析**
- [ ] 识别核心使用的 API 服务
- [ ] 评估直接对接的可行性
- [ ] 开发 API 管理层
- [ ] 集成开源数据源

**任务 5.2: 服务集成测试**
- [ ] 搜索功能测试
- [ ] 爬虫功能测试
- [ ] API 服务测试
- [ ] 性能和稳定性测试

### 阶段三：监控和优化（预计 2-3 周）

#### Week 11-12: 监控系统

**任务 6.1: Prometheus + Grafana 部署**
- [ ] 部署监控基础设施
- [ ] 配置指标收集
- [ ] 创建监控面板
- [ ] 设置告警规则

**任务 6.2: LLM 追踪服务**
- [ ] 开发 LLM 调用追踪
- [ ] 实现性能指标收集
- [ ] 创建分析报告
- [ ] 集成到现有系统

#### Week 13: 最终优化和部署

**任务 7.1: 性能优化**
- [ ] 系统性能调优
- [ ] 资源使用优化
- [ ] 缓存策略优化
- [ ] 数据库查询优化

**任务 7.2: 生产部署准备**
- [ ] 生产环境配置
- [ ] 备份和恢复策略
- [ ] 监控和告警配置
- [ ] 文档完善

## 技术实现细节

### 1. 数据库迁移脚本

```python
# 示例：Supabase 到 PostgreSQL 迁移
import psycopg2
from supabase import create_client

def migrate_database():
    # 连接源数据库（Supabase）
    supabase = create_client(supabase_url, supabase_key)
    
    # 连接目标数据库（PostgreSQL）
    pg_conn = psycopg2.connect(
        host="localhost",
        database="suna",
        user="postgres",
        password="password"
    )
    
    # 迁移逻辑
    # ...
```

### 2. 沙盒管理服务架构

```python
# 示例：沙盒管理 API
from fastapi import FastAPI
import docker

app = FastAPI()
client = docker.from_env()

@app.post("/sandbox/create")
async def create_sandbox(config: SandboxConfig):
    container = client.containers.run(
        image=config.image,
        detach=True,
        mem_limit=config.memory_limit,
        cpu_quota=config.cpu_quota,
        network_mode="bridge"
    )
    return {"sandbox_id": container.id}
```

### 3. 搜索服务包装器

```python
# 示例：SearXNG API 包装器
import httpx
from typing import List, Dict

class SearchService:
    def __init__(self, searxng_url: str):
        self.base_url = searxng_url
        
    async def search(self, query: str, category: str = "general") -> List[Dict]:
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{self.base_url}/search",
                params={
                    "q": query,
                    "category": category,
                    "format": "json"
                }
            )
            return response.json()["results"]
```

## 部署配置

### Docker Compose 配置示例

```yaml
version: '3.8'
services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: suna
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  postgrest:
    image: postgrest/postgrest:latest
    environment:
      PGRST_DB_URI: postgres://postgres:password@postgres:5432/suna
      PGRST_DB_SCHEMA: public
      PGRST_DB_ANON_ROLE: anon
    ports:
      - "3000:3000"
    depends_on:
      - postgres

  gotrue:
    image: supabase/gotrue:latest
    environment:
      GOTRUE_API_HOST: 0.0.0.0
      GOTRUE_API_PORT: 9999
      GOTRUE_DB_DRIVER: postgres
      DATABASE_URL: postgres://postgres:password@postgres:5432/suna
    ports:
      - "9999:9999"
    depends_on:
      - postgres

  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000"
      - "9001:9001"

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  rabbitmq:
    image: rabbitmq:3-management
    environment:
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: admin
    ports:
      - "5672:5672"
      - "15672:15672"

  searxng:
    image: searxng/searxng:latest
    ports:
      - "8080:8080"
    volumes:
      - ./searxng:/etc/searxng

  sandbox-manager:
    build: ./sandbox-manager
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "8001:8000"
    environment:
      DOCKER_HOST: unix:///var/run/docker.sock

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: admin
    volumes:
      - grafana_data:/var/lib/grafana

volumes:
  postgres_data:
  minio_data:
  grafana_data:
```

## 风险评估和缓解策略

### 技术风险
1. **数据迁移风险**
   - 缓解：分阶段迁移，完整备份，回滚计划
   
2. **性能下降风险**
   - 缓解：性能基准测试，逐步优化，监控告警
   
3. **兼容性问题**
   - 缓解：API 兼容层，渐进式替换，充分测试

### 运营风险
1. **服务稳定性**
   - 缓解：高可用部署，监控告警，故障恢复
   
2. **维护复杂度**
   - 缓解：自动化部署，文档完善，团队培训

## 成功指标

### 功能指标
- [ ] 所有现有功能正常工作
- [ ] API 响应时间不超过原来的 150%
- [ ] 系统可用性 > 99.5%

### 技术指标
- [ ] 零第三方商业服务依赖
- [ ] 完整的监控和告警体系
- [ ] 自动化部署和运维

### 业务指标
- [ ] 运营成本降低 > 60%
- [ ] 数据完全自主可控
- [ ] 支持私有化部署

## 后续规划

### 短期（1-3个月）
- 系统稳定性优化
- 性能调优和扩展
- 用户反馈收集和改进

### 中期（3-6个月）
- 高可用架构升级
- 多租户支持
- 国际化和本地化

### 长期（6-12个月）
- 云原生架构改造
- 微服务拆分
- AI 能力增强

## 团队分工建议

### 后端开发（2人）
- 数据库迁移和 API 开发
- 沙盒管理服务开发
- 搜索和爬虫服务开发

### 前端开发（1人）
- 前端适配和测试
- 用户界面优化
- 用户体验改进

### DevOps（1人）
- 基础设施部署
- 监控系统搭建
- 自动化运维

### 测试（1人）
- 功能测试和回归测试
- 性能测试和压力测试
- 安全测试和漏洞扫描

---

**注意：本计划为初步规划，具体实施时需要根据实际情况进行调整和优化。建议在每个阶段结束后进行回顾和总结，及时调整后续计划。**